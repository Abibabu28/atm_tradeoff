{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbac74c5-2598-4117-8dfe-e435c51a34b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Adaptive Trade-off Model (ATM) Implementation for Federated Distributed Environment\n",
    "# Jupyter Notebook Version\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure logging for Jupyter\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"ATM_Federated\")\n",
    "\n",
    "# Create a handler that will store logs for display\n",
    "class NotebookLogHandler(logging.Handler):\n",
    "    def __init__(self, max_logs=100):\n",
    "        super().__init__()\n",
    "        self.logs = []\n",
    "        self.max_logs = max_logs\n",
    "        \n",
    "    def emit(self, record):\n",
    "        log_entry = self.format(record)\n",
    "        self.logs.append(log_entry)\n",
    "        if len(self.logs) > self.max_logs:\n",
    "            self.logs.pop(0)\n",
    "\n",
    "notebook_handler = NotebookLogHandler()\n",
    "logger.addHandler(notebook_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9935ba14-f1cc-43db-a9d3-585f68d972e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display function for logs\n",
    "def display_logs():\n",
    "    clear_output(wait=True)\n",
    "    for log in notebook_handler.logs:\n",
    "        print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9425f68a-eff9-4467-95ad-b44eae10e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCollector:\n",
    "    \"\"\"Simulates Prometheus metrics collection in a distributed environment\"\"\"\n",
    "    \n",
    "    def __init__(self, node_id: str):\n",
    "        self.node_id = node_id\n",
    "        self.metrics = {}\n",
    "        \n",
    "    def collect_node_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Collect system metrics for this node\"\"\"\n",
    "        # In a real system, this would interface with Prometheus API\n",
    "        # Simulating metrics collection\n",
    "        self.metrics = {\n",
    "            \"cpu_utilization\": np.random.uniform(0.3, 0.95),  # 30-95%\n",
    "            \"memory_utilization\": np.random.uniform(0.4, 0.8),  # 40-80%\n",
    "            \"network_latency_ms\": np.random.uniform(5, 200),  # 5-200ms\n",
    "            \"network_throughput_mbps\": np.random.uniform(50, 1000),  # 50-1000 Mbps\n",
    "            \"disk_io_utilization\": np.random.uniform(0.1, 0.7),  # 10-70%\n",
    "            \"timestamp\": time.time(),\n",
    "            \"node_id\": self.node_id\n",
    "        }\n",
    "        return self.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff286d78-aeb0-478c-a6d6-9659d5d48de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KafkaProducer:\n",
    "    \"\"\"Simulates Kafka producer for sending metrics and events\"\"\"\n",
    "    \n",
    "    def __init__(self, broker_address: str = \"kafka:9092\"):\n",
    "        self.broker_address = broker_address\n",
    "        self.message_count = 0\n",
    "        print(f\"Initialized Kafka producer connecting to {broker_address}\")\n",
    "        \n",
    "    def send_message(self, topic: str, message: Dict) -> bool:\n",
    "        \"\"\"Send a message to a Kafka topic\"\"\"\n",
    "        # In a real system, this would use kafka-python or similar\n",
    "        print(f\"Sending to topic {topic}: {message}\")\n",
    "        self.message_count += 1\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9bf0022-2130-4b69-b8e4-bdeaa885ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KafkaProducer:\n",
    "    \"\"\"Simulates Kafka producer for sending metrics and events\"\"\"\n",
    "    \n",
    "    def __init__(self, broker_address: str = \"kafka:9092\"):\n",
    "        self.broker_address = broker_address\n",
    "        self.message_count = 0\n",
    "        print(f\"Initialized Kafka producer connecting to {broker_address}\")\n",
    "        \n",
    "    def send_message(self, topic: str, message: Dict) -> bool:\n",
    "        \"\"\"Send a message to a Kafka topic\"\"\"\n",
    "        # In a real system, this would use kafka-python or similar\n",
    "        print(f\"Sending to topic {topic}: {message}\")\n",
    "        self.message_count += 1\n",
    "        return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d52e370-4b48-40fd-a3ca-3946e2fb4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KafkaConsumer:\n",
    "    \"\"\"Simulates Kafka consumer for receiving metrics and commands\"\"\"\n",
    "    \n",
    "    def __init__(self, topics: List[str], group_id: str, broker_address: str = \"kafka:9092\"):\n",
    "        self.topics = topics\n",
    "        self.group_id = group_id\n",
    "        self.broker_address = broker_address\n",
    "        self.message_queue = queue.Queue()\n",
    "        self.running = True\n",
    "        print(f\"Initialized Kafka consumer for topics {topics}, group {group_id}\")\n",
    "        \n",
    "        # Start simulated message consumption thread\n",
    "        self.consumer_thread = threading.Thread(target=self._consume_messages)\n",
    "        self.consumer_thread.daemon = True\n",
    "        self.consumer_thread.start()\n",
    "        \n",
    "    def _consume_messages(self):\n",
    "        \"\"\"Background thread that simulates message consumption\"\"\"\n",
    "        while self.running:\n",
    "            # In a real system, this would poll Kafka topics\n",
    "            time.sleep(1)\n",
    "            # Simulate receiving random messages\n",
    "            if np.random.random() < 0.7:  # 70% chance of receiving a message each second\n",
    "                self.message_queue.put({\n",
    "                    \"type\": np.random.choice([\"metrics\", \"command\"]),\n",
    "                    \"content\": {\n",
    "                        \"value\": np.random.random(),\n",
    "                        \"timestamp\": time.time()\n",
    "                    }\n",
    "                })\n",
    "    \n",
    "    def poll(self, timeout_ms: int = 100) -> List[Dict]:\n",
    "        \"\"\"Poll for new messages\"\"\"\n",
    "        messages = []\n",
    "        try:\n",
    "            while not self.message_queue.empty():\n",
    "                messages.append(self.message_queue.get(block=False))\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        return messages\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Stop the consumer\"\"\"\n",
    "        self.running = False\n",
    "        if self.consumer_thread.is_alive():\n",
    "            self.consumer_thread.join(timeout=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d91f781-08c1-4a05-a96a-7266570f7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReinforcementLearningEngine:\n",
    "    \"\"\"Decision engine using Reinforcement Learning to optimize workload distribution\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize Q-learning parameters\n",
    "        self.states = []  # States represent different system conditions\n",
    "        self.actions = [\"balanced\", \"distribution_heavy\", \"local_heavy\"]\n",
    "        self.q_table = {}  # Q-table for storing state-action values\n",
    "        self.learning_rate = 0.1\n",
    "        self.discount_factor = 0.9\n",
    "        self.exploration_rate = 0.2\n",
    "        self.exploration_decay = 0.995\n",
    "        \n",
    "    def _get_state_key(self, metrics: Dict[str, Any]) -> str:\n",
    "        \"\"\"Convert system metrics to a discrete state representation\"\"\"\n",
    "        # Discretize continuous metrics into state bins\n",
    "        cpu_bin = int(metrics[\"cpu_utilization\"] * 10)\n",
    "        mem_bin = int(metrics[\"memory_utilization\"] * 10)\n",
    "        latency_bin = min(9, int(metrics[\"network_latency_ms\"] / 20))\n",
    "        throughput_bin = min(9, int(metrics[\"network_throughput_mbps\"] / 100))\n",
    "        \n",
    "        return f\"{cpu_bin}_{mem_bin}_{latency_bin}_{throughput_bin}\"\n",
    "    \n",
    "    def decide_strategy(self, metrics: Dict[str, Any]) -> str:\n",
    "        \"\"\"Determine the optimal strategy based on current metrics\"\"\"\n",
    "        state_key = self._get_state_key(metrics)\n",
    "        \n",
    "        # Add state to Q-table if not seen before\n",
    "        if state_key not in self.q_table:\n",
    "            self.q_table[state_key] = {action: 0.0 for action in self.actions}\n",
    "        \n",
    "        # Exploration vs. exploitation\n",
    "        if np.random.random() < self.exploration_rate:\n",
    "            # Explore: choose random action\n",
    "            chosen_action = np.random.choice(self.actions)\n",
    "            print(f\"Exploring with action: {chosen_action}\")\n",
    "        else:\n",
    "            # Exploit: choose best action from Q-table\n",
    "            chosen_action = max(self.q_table[state_key], key=self.q_table[state_key].get)\n",
    "            print(f\"Exploiting with action: {chosen_action}\")\n",
    "        \n",
    "        # Decay exploration rate\n",
    "        self.exploration_rate *= self.exploration_decay\n",
    "        \n",
    "        return chosen_action\n",
    "    \n",
    "    def update_q_table(self, prev_state: str, action: str, reward: float, new_state: str) -> None:\n",
    "        \"\"\"Update Q-values based on reward and new state\"\"\"\n",
    "        if new_state not in self.q_table:\n",
    "            self.q_table[new_state] = {act: 0.0 for act in self.actions}\n",
    "            \n",
    "        # Q-learning update rule\n",
    "        # Q(s,a) = Q(s,a) + α * [r + γ * max(Q(s',a')) - Q(s,a)]\n",
    "        old_value = self.q_table[prev_state][action]\n",
    "        next_max = max(self.q_table[new_state].values())\n",
    "        \n",
    "        # Calculate new Q-value\n",
    "        new_value = old_value + self.learning_rate * (\n",
    "            reward + self.discount_factor * next_max - old_value\n",
    "        )\n",
    "        \n",
    "        # Update Q-table\n",
    "        self.q_table[prev_state][action] = new_value\n",
    "        print(f\"Updated Q-value for {prev_state}, {action}: {old_value} -> {new_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a896ccd-7dfa-44b3-9171-661e829f062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_table(self, prev_state: str, action: str, reward: float, new_state: str) -> None:\n",
    "        \"\"\"Update Q-values based on reward and new state\"\"\"\n",
    "        if new_state not in self.q_table:\n",
    "            self.q_table[new_state] = {act: 0.0 for act in self.actions}\n",
    "            \n",
    "        # Q-learning update rule\n",
    "        # Q(s,a) = Q(s,a) + α * [r + γ * max(Q(s',a')) - Q(s,a)]\n",
    "        old_value = self.q_table[prev_state][action]\n",
    "        next_max = max(self.q_table[new_state].values())\n",
    "        \n",
    "        # Calculate new Q-value\n",
    "        new_value = old_value + self.learning_rate * (\n",
    "            reward + self.discount_factor * next_max - old_value\n",
    "        )\n",
    "        \n",
    "        # Update Q-table\n",
    "        self.q_table[prev_state][action] = new_value\n",
    "        print(f\"Updated Q-value for {prev_state}, {action}: {old_value} -> {new_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7347d75-956f-4035-a8e0-d1ed61d072f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecutionController:\n",
    "    \"\"\"Controls the distributed execution strategy based on decisions\"\"\"\n",
    "    \n",
    "    def __init__(self, node_id: str):\n",
    "        self.node_id = node_id\n",
    "        self.current_mode = \"balanced\"  # Default mode\n",
    "        self.mode_params = {\n",
    "            \"balanced\": {\n",
    "                \"local_compute_ratio\": 0.5,\n",
    "                \"network_batch_size\": 1000,\n",
    "                \"consistency_level\": \"strong\"\n",
    "            },\n",
    "            \"distribution_heavy\": {\n",
    "                \"local_compute_ratio\": 0.2,\n",
    "                \"network_batch_size\": 5000,\n",
    "                \"consistency_level\": \"eventual\"\n",
    "            },\n",
    "            \"local_heavy\": {\n",
    "                \"local_compute_ratio\": 0.8,\n",
    "                \"network_batch_size\": 100,\n",
    "                \"consistency_level\": \"strong\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def apply_strategy(self, mode: str) -> Dict[str, Any]:\n",
    "        \"\"\"Apply the specified execution strategy\"\"\"\n",
    "        if mode not in self.mode_params:\n",
    "            print(f\"Unknown mode: {mode}, keeping current mode\")\n",
    "            return\n",
    "        \n",
    "        self.current_mode = mode\n",
    "        params = self.mode_params[mode]\n",
    "        \n",
    "        print(f\"Node {self.node_id} switching to {mode} mode with params: {params}\")\n",
    "        \n",
    "        # Here we would actually adjust system parameters\n",
    "        # For simulation, we'll just return the parameters\n",
    "        return params\n",
    "    \n",
    "    def get_current_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get current configuration parameters\"\"\"\n",
    "        return {\n",
    "            \"mode\": self.current_mode,\n",
    "            \"params\": self.mode_params[self.current_mode],\n",
    "            \"node_id\": self.node_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8536e0b1-c150-4640-89c0-f45652cc35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackCollector:\n",
    "    \"\"\"Collects performance metrics after applying a strategy for feedback\"\"\"\n",
    "    \n",
    "    def __init__(self, node_id: str):\n",
    "        self.node_id = node_id\n",
    "        self.baseline_metrics = {}\n",
    "        self.current_metrics = {}\n",
    "        self.performance_history = []\n",
    "        \n",
    "    def set_baseline(self, metrics: Dict[str, Any]) -> None:\n",
    "        \"\"\"Set baseline metrics for comparison\"\"\"\n",
    "        self.baseline_metrics = metrics.copy()\n",
    "        \n",
    "    def collect_current_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Collect current performance metrics\"\"\"\n",
    "        # In real system, would interface with monitoring system\n",
    "        # Simulating metrics collection\n",
    "        self.current_metrics = {\n",
    "            \"response_time_ms\": np.random.uniform(10, 500),\n",
    "            \"throughput_qps\": np.random.uniform(100, 10000),\n",
    "            \"error_rate\": np.random.uniform(0, 0.05),\n",
    "            \"timestamp\": time.time(),\n",
    "            \"node_id\": self.node_id\n",
    "        }\n",
    "        return self.current_metrics\n",
    "    \n",
    "    def calculate_reward(self) -> float:\n",
    "        \"\"\"Calculate reward based on performance improvement\"\"\"\n",
    "        # No baseline yet\n",
    "        if not self.baseline_metrics:\n",
    "            return 0.0\n",
    "            \n",
    "        # Simple reward function based on response time improvement\n",
    "        # Could be much more sophisticated in real system\n",
    "        baseline_rt = self.baseline_metrics.get(\"response_time_ms\", 0)\n",
    "        current_rt = self.current_metrics.get(\"response_time_ms\", 0)\n",
    "        \n",
    "        if baseline_rt == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        # Improvement ratio: lower response time is better\n",
    "        improvement = (baseline_rt - current_rt) / baseline_rt\n",
    "        \n",
    "        # Bound the reward\n",
    "        reward = min(5.0, max(-5.0, improvement * 10))\n",
    "        \n",
    "        # Record performance\n",
    "        self.performance_history.append({\n",
    "            \"timestamp\": time.time(),\n",
    "            \"baseline_rt\": baseline_rt,\n",
    "            \"current_rt\": current_rt,\n",
    "            \"improvement\": improvement,\n",
    "            \"reward\": reward\n",
    "        })\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "114f7ee2-f532-4295-a4c9-a31d1632a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedNode:\n",
    "    \"\"\"Represents a node in the federated distributed system\"\"\"\n",
    "    \n",
    "    def __init__(self, node_id: str, coordinator_address: str = None):\n",
    "        self.node_id = node_id\n",
    "        self.coordinator_address = coordinator_address\n",
    "        self.is_coordinator = coordinator_address is None\n",
    "        \n",
    "        # Initialize components\n",
    "        self.metrics_collector = MetricsCollector(node_id)\n",
    "        self.kafka_producer = KafkaProducer()\n",
    "        self.kafka_consumer = KafkaConsumer(\n",
    "            topics=[\"atm_commands\", \"atm_metrics\"],\n",
    "            group_id=f\"node_{node_id}\"\n",
    "        )\n",
    "        self.execution_controller = ExecutionController(node_id)\n",
    "        self.feedback_collector = FeedbackCollector(node_id)\n",
    "        \n",
    "        # Only coordinator nodes have decision engine\n",
    "        self.decision_engine = ReinforcementLearningEngine() if self.is_coordinator else None\n",
    "        \n",
    "        # State tracking\n",
    "        self.prev_state = None\n",
    "        self.current_action = \"balanced\"\n",
    "        self.running = True\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.strategy_history = []\n",
    "        self.metrics_history = []\n",
    "        \n",
    "        print(f\"Initialized {'coordinator' if self.is_coordinator else 'worker'} node {node_id}\")\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the node operation\"\"\"\n",
    "        print(f\"Starting node {self.node_id}\")\n",
    "        \n",
    "        try:\n",
    "            if self.is_coordinator:\n",
    "                self._run_coordinator()\n",
    "            else:\n",
    "                self._run_worker()\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Shutdown signal received\")\n",
    "        finally:\n",
    "            self.shutdown()\n",
    "    \n",
    "    def _run_coordinator(self):\n",
    "        \"\"\"Run the coordinator node logic\"\"\"\n",
    "        print(f\"Running as coordinator node {self.node_id}\")\n",
    "        \n",
    "        while self.running:\n",
    "            # 1. Collect local metrics\n",
    "            local_metrics = self.metrics_collector.collect_node_metrics()\n",
    "            self.metrics_history.append(local_metrics)\n",
    "            \n",
    "            # 2. Collect metrics from all worker nodes via Kafka\n",
    "            cluster_metrics = self._aggregate_cluster_metrics()\n",
    "            \n",
    "            # 3. Make optimization decision\n",
    "            if cluster_metrics:\n",
    "                state_key = self.decision_engine._get_state_key(local_metrics)\n",
    "                new_action = self.decision_engine.decide_strategy(local_metrics)\n",
    "                \n",
    "                # Track strategy changes\n",
    "                self.strategy_history.append({\n",
    "                    \"timestamp\": time.time(),\n",
    "                    \"strategy\": new_action,\n",
    "                    \"state\": state_key\n",
    "                })\n",
    "                \n",
    "                # 4. Distribute decision to all nodes\n",
    "                command = {\n",
    "                    \"type\": \"strategy_change\",\n",
    "                    \"mode\": new_action,\n",
    "                    \"timestamp\": time.time(),\n",
    "                    \"source_node\": self.node_id\n",
    "                }\n",
    "                self.kafka_producer.send_message(\"atm_commands\", command)\n",
    "                \n",
    "                # 5. Apply strategy locally too\n",
    "                self.execution_controller.apply_strategy(new_action)\n",
    "                \n",
    "                # 6. Store current state/action for later update\n",
    "                self.prev_state = state_key\n",
    "                self.current_action = new_action\n",
    "                \n",
    "                # 7. Set baseline for feedback\n",
    "                self.feedback_collector.set_baseline(local_metrics)\n",
    "            \n",
    "            # 8. Wait for feedback cycle\n",
    "            time.sleep(10)  # Adjust as needed\n",
    "            \n",
    "            # 9. Collect feedback and update model\n",
    "            current_metrics = self.feedback_collector.collect_current_metrics()\n",
    "            reward = self.feedback_collector.calculate_reward()\n",
    "            \n",
    "            if self.prev_state:\n",
    "                new_state = self.decision_engine._get_state_key(\n",
    "                    self.metrics_collector.collect_node_metrics()\n",
    "                )\n",
    "                self.decision_engine.update_q_table(\n",
    "                    self.prev_state, self.current_action, reward, new_state\n",
    "                )\n",
    "                print(f\"Updated model with reward {reward:.2f} for action {self.current_action}\")\n",
    "    \n",
    "    def _run_worker(self):\n",
    "        \"\"\"Run the worker node logic\"\"\"\n",
    "        print(f\"Running as worker node {self.node_id}\")\n",
    "        \n",
    "        while self.running:\n",
    "            # 1. Collect and publish metrics\n",
    "            metrics = self.metrics_collector.collect_node_metrics()\n",
    "            self.metrics_history.append(metrics)\n",
    "            self.kafka_producer.send_message(\"atm_metrics\", metrics)\n",
    "            \n",
    "            # 2. Check for commands from coordinator\n",
    "            messages = self.kafka_consumer.poll()\n",
    "            for message in messages:\n",
    "                if message.get(\"type\") == \"command\" and \"content\" in message:\n",
    "                    command = message[\"content\"]\n",
    "                    if command.get(\"type\") == \"strategy_change\":\n",
    "                        # Apply requested strategy\n",
    "                        mode = command.get(\"mode\", \"balanced\")\n",
    "                        self.execution_controller.apply_strategy(mode)\n",
    "                        \n",
    "                        # Track strategy changes\n",
    "                        self.strategy_history.append({\n",
    "                            \"timestamp\": time.time(),\n",
    "                            \"strategy\": mode,\n",
    "                            \"source\": \"coordinator\"\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"Applied strategy {mode} based on coordinator command\")\n",
    "                \n",
    "            # 3. Collect feedback for local performance monitoring\n",
    "            self.feedback_collector.collect_current_metrics()\n",
    "            \n",
    "            # 4. Wait before next cycle\n",
    "            time.sleep(5)  # Adjust as needed\n",
    "    \n",
    "    def _aggregate_cluster_metrics(self) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        \"\"\"Aggregate metrics from all nodes in the cluster\"\"\"\n",
    "        # In a real system, this would collect and process Kafka metrics\n",
    "        # For simulation, we'll return some dummy cluster data\n",
    "        return {\n",
    "            \"nodes\": [\n",
    "                {\"node_id\": f\"node_{i}\", \n",
    "                 \"cpu\": np.random.uniform(0.3, 0.9),\n",
    "                 \"memory\": np.random.uniform(0.4, 0.8),\n",
    "                 \"network_latency\": np.random.uniform(5, 200)\n",
    "                } for i in range(1, 6)  # Simulate 5 nodes\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def shutdown(self):\n",
    "        \"\"\"Shutdown the node gracefully\"\"\"\n",
    "        print(f\"Shutting down node {self.node_id}\")\n",
    "        self.running = False\n",
    "        self.kafka_consumer.close()\n",
    "        # Additional cleanup as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5512e7a-7315-4b4e-8117-4c794190c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATMCluster:\n",
    "    \"\"\"Manages a cluster of ATM nodes\"\"\"\n",
    "    \n",
    "    def __init__(self, num_nodes: int = 5):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.nodes = []\n",
    "        \n",
    "    def start_cluster(self):\n",
    "        \"\"\"Start the ATM cluster with one coordinator and multiple workers\"\"\"\n",
    "        print(f\"Starting ATM cluster with {self.num_nodes} nodes\")\n",
    "        \n",
    "        # Create coordinator node\n",
    "        coordinator = FederatedNode(node_id=\"coordinator\")\n",
    "        self.nodes.append(coordinator)\n",
    "        \n",
    "        # Create worker nodes\n",
    "        for i in range(1, self.num_nodes):\n",
    "            worker = FederatedNode(\n",
    "                node_id=f\"worker_{i}\",\n",
    "                coordinator_address=\"coordinator:8080\"  # In real system, use actual address\n",
    "            )\n",
    "            self.nodes.append(worker)\n",
    "        \n",
    "        # Start all nodes in separate threads\n",
    "        with ThreadPoolExecutor(max_workers=self.num_nodes) as executor:\n",
    "            futures = [executor.submit(node.start) for node in self.nodes]\n",
    "            \n",
    "            # Wait for completion or handle exceptions\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "    \n",
    "    def shutdown_cluster(self):\n",
    "        \"\"\"Shutdown all nodes in the cluster\"\"\"\n",
    "        print(\"Shutting down ATM cluster\")\n",
    "        for node in self.nodes:\n",
    "            node.shutdown()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979190e-6029-45e1-b588-11481de51994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Adaptive Trade-off Model (ATM) in federated mode\n",
      "Starting ATM cluster with 5 nodes\n",
      "Initialized Kafka producer connecting to kafka:9092\n",
      "Initialized Kafka consumer for topics ['atm_commands', 'atm_metrics'], group node_coordinator\n",
      "Initialized coordinator node coordinator\n",
      "Initialized Kafka producer connecting to kafka:9092\n",
      "Initialized Kafka consumer for topics ['atm_commands', 'atm_metrics'], group node_worker_1\n",
      "Initialized worker node worker_1\n",
      "Initialized Kafka producer connecting to kafka:9092\n",
      "Initialized Kafka consumer for topics ['atm_commands', 'atm_metrics'], group node_worker_2\n",
      "Initialized worker node worker_2\n",
      "Initialized Kafka producer connecting to kafka:9092\n",
      "Initialized Kafka consumer for topics ['atm_commands', 'atm_metrics'], group node_worker_3\n",
      "Initialized worker node worker_3\n",
      "Initialized Kafka producer connecting to kafka:9092\n",
      "Initialized Kafka consumer for topics ['atm_commands', 'atm_metrics'], group node_worker_4\n",
      "Initialized worker node worker_4\n",
      "Starting node coordinator\n",
      "Running as coordinator node coordinator\n",
      "Exploiting with action: balanced\n",
      "Sending to topic atm_commands: {'type': 'strategy_change', 'mode': 'balanced', 'timestamp': 1742430189.510838, 'source_node': 'coordinator'}\n",
      "Node coordinator switching to balanced mode with params: {'local_compute_ratio': 0.5, 'network_batch_size': 1000, 'consistency_level': 'strong'}\n",
      "Starting node worker_1\n",
      "Running as worker node worker_1\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.3431766764121117, 'memory_utilization': 0.6569972773219253, 'network_latency_ms': 91.25875021527932, 'network_throughput_mbps': 898.0678293437444, 'disk_io_utilization': 0.11140932354669038, 'timestamp': 1742430189.5110831, 'node_id': 'worker_1'}\n",
      "Starting node worker_2\n",
      "Running as worker node worker_2\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.33571774794772985, 'memory_utilization': 0.6349211011584744, 'network_latency_ms': 89.98015023332445, 'network_throughput_mbps': 756.1444737980631, 'disk_io_utilization': 0.18283908948784233, 'timestamp': 1742430189.511245, 'node_id': 'worker_2'}\n",
      "Starting node worker_3\n",
      "Running as worker node worker_3\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.4123243485228241, 'memory_utilization': 0.587801288936435, 'network_latency_ms': 94.15572872312785, 'network_throughput_mbps': 691.7561285503724, 'disk_io_utilization': 0.4421089355592086, 'timestamp': 1742430189.511389, 'node_id': 'worker_3'}\n",
      "Starting node worker_4\n",
      "Running as worker node worker_4\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.7034285915441116, 'memory_utilization': 0.43014923440595776, 'network_latency_ms': 9.39157485206154, 'network_throughput_mbps': 90.41657916605456, 'disk_io_utilization': 0.3145908484470408, 'timestamp': 1742430189.511523, 'node_id': 'worker_4'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.6680494595566104, 'memory_utilization': 0.42282589903961965, 'network_latency_ms': 12.848361356127723, 'network_throughput_mbps': 526.729524103775, 'disk_io_utilization': 0.616350139567735, 'timestamp': 1742430194.51173, 'node_id': 'worker_1'}Sending to topic atm_metrics: {'cpu_utilization': 0.7996229878670864, 'memory_utilization': 0.7814320245585241, 'network_latency_ms': 42.39466279453495, 'network_throughput_mbps': 208.69407087576724, 'disk_io_utilization': 0.6702441393356698, 'timestamp': 1742430194.5129101, 'node_id': 'worker_4'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.4020150136562245, 'memory_utilization': 0.479787168347439, 'network_latency_ms': 158.93863694198524, 'network_throughput_mbps': 737.4914836748225, 'disk_io_utilization': 0.17514225726303073, 'timestamp': 1742430194.513153, 'node_id': 'worker_2'}\n",
      "\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.5242419472259162, 'memory_utilization': 0.4653450647138125, 'network_latency_ms': 174.748982649091, 'network_throughput_mbps': 956.5116672204048, 'disk_io_utilization': 0.1589897189555897, 'timestamp': 1742430194.513441, 'node_id': 'worker_3'}\n",
      "Updated Q-value for 4_5_8_8, balanced: 0.0 -> 0.0\n",
      "Updated model with reward 0.00 for action balanced\n",
      "Exploiting with action: balanced\n",
      "Sending to topic atm_commands: {'type': 'strategy_change', 'mode': 'balanced', 'timestamp': 1742430199.517055, 'source_node': 'coordinator'}\n",
      "Node coordinator switching to balanced mode with params: {'local_compute_ratio': 0.5, 'network_batch_size': 1000, 'consistency_level': 'strong'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.4342712033092009, 'memory_utilization': 0.565941176020301, 'network_latency_ms': 191.8372661312549, 'network_throughput_mbps': 117.36728459464115, 'disk_io_utilization': 0.3755239856004102, 'timestamp': 1742430199.517317, 'node_id': 'worker_4'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.6628260182749168, 'memory_utilization': 0.7573949996553412, 'network_latency_ms': 32.93293321143566, 'network_throughput_mbps': 399.0526747990234, 'disk_io_utilization': 0.4066317960304965, 'timestamp': 1742430199.5175512, 'node_id': 'worker_1'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.5797095679040143, 'memory_utilization': 0.7401983193934935, 'network_latency_ms': 129.26023123543376, 'network_throughput_mbps': 591.8787698023224, 'disk_io_utilization': 0.4229108988855387, 'timestamp': 1742430199.517736, 'node_id': 'worker_3'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.4483211527581825, 'memory_utilization': 0.7710656126301098, 'network_latency_ms': 101.07386248246327, 'network_throughput_mbps': 308.4895859285539, 'disk_io_utilization': 0.4763117491382538, 'timestamp': 1742430199.517909, 'node_id': 'worker_2'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.5432943534121567, 'memory_utilization': 0.5863345986286584, 'network_latency_ms': 149.13074524394625, 'network_throughput_mbps': 820.6114020289659, 'disk_io_utilization': 0.450030270126211, 'timestamp': 1742430204.5178418, 'node_id': 'worker_1'}Sending to topic atm_metrics: {'cpu_utilization': 0.46963413995815606, 'memory_utilization': 0.5399047738489732, 'network_latency_ms': 70.85138636006943, 'network_throughput_mbps': 818.7894071476295, 'disk_io_utilization': 0.210248827988192, 'timestamp': 1742430204.518007, 'node_id': 'worker_4'}\n",
      "\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.39495103446835705, 'memory_utilization': 0.5689226100223032, 'network_latency_ms': 120.32016873359497, 'network_throughput_mbps': 857.715791936174, 'disk_io_utilization': 0.34688370991886486, 'timestamp': 1742430204.518883, 'node_id': 'worker_2'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.6296212393241439, 'memory_utilization': 0.6409235209990405, 'network_latency_ms': 120.67510889288705, 'network_throughput_mbps': 844.3300916425525, 'disk_io_utilization': 0.21656067786383834, 'timestamp': 1742430204.519031, 'node_id': 'worker_3'}\n",
      "Updated Q-value for 4_5_3_3, balanced: 0.0 -> 0.0\n",
      "Updated model with reward 0.00 for action balanced\n",
      "Exploiting with action: balanced\n",
      "Sending to topic atm_commands: {'type': 'strategy_change', 'mode': 'balanced', 'timestamp': 1742430209.518893, 'source_node': 'coordinator'}\n",
      "Node coordinator switching to balanced mode with params: {'local_compute_ratio': 0.5, 'network_batch_size': 1000, 'consistency_level': 'strong'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.6872033017074699, 'memory_utilization': 0.6633841096708364, 'network_latency_ms': 185.10422379210834, 'network_throughput_mbps': 653.4003998572787, 'disk_io_utilization': 0.49537255184318896, 'timestamp': 1742430209.519497, 'node_id': 'worker_1'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.6767376184353524, 'memory_utilization': 0.5569344083477865, 'network_latency_ms': 104.35056490911757, 'network_throughput_mbps': 534.8326110445155, 'disk_io_utilization': 0.6318899466944485, 'timestamp': 1742430209.519708, 'node_id': 'worker_4'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.8494699598553663, 'memory_utilization': 0.5282389118195296, 'network_latency_ms': 137.93168590559088, 'network_throughput_mbps': 615.6328839016822, 'disk_io_utilization': 0.3578278145854621, 'timestamp': 1742430209.523613, 'node_id': 'worker_2'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.4546891741350064, 'memory_utilization': 0.7762420347839347, 'network_latency_ms': 20.776563767324436, 'network_throughput_mbps': 299.2371071957226, 'disk_io_utilization': 0.5682026692703678, 'timestamp': 1742430209.523885, 'node_id': 'worker_3'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.9156955963864475, 'memory_utilization': 0.7412272886281598, 'network_latency_ms': 148.46326286101953, 'network_throughput_mbps': 373.87792898434986, 'disk_io_utilization': 0.574604134814675, 'timestamp': 1742430214.520161, 'node_id': 'worker_1'}Sending to topic atm_metrics: {'cpu_utilization': 0.5758927879569418, 'memory_utilization': 0.7191839653511372, 'network_latency_ms': 11.980131915713551, 'network_throughput_mbps': 834.7906919365628, 'disk_io_utilization': 0.33666850623229716, 'timestamp': 1742430214.520401, 'node_id': 'worker_4'}\n",
      "\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.31303443311766227, 'memory_utilization': 0.7829138802005838, 'network_latency_ms': 171.9655900327056, 'network_throughput_mbps': 150.57517559375617, 'disk_io_utilization': 0.45057497745451836, 'timestamp': 1742430214.528867, 'node_id': 'worker_2'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.3617437909585288, 'memory_utilization': 0.7483666298522917, 'network_latency_ms': 191.36426326405999, 'network_throughput_mbps': 405.686690154636, 'disk_io_utilization': 0.3860745118626058, 'timestamp': 1742430214.5291579, 'node_id': 'worker_3'}\n",
      "Updated Q-value for 8_6_2_9, balanced: 0.0 -> 0.0\n",
      "Updated model with reward 0.00 for action balanced\n",
      "Exploiting with action: balanced\n",
      "Sending to topic atm_commands: {'type': 'strategy_change', 'mode': 'balanced', 'timestamp': 1742430219.524582, 'source_node': 'coordinator'}\n",
      "Node coordinator switching to balanced mode with params: {'local_compute_ratio': 0.5, 'network_batch_size': 1000, 'consistency_level': 'strong'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.5152520787562906, 'memory_utilization': 0.4801960892071441, 'network_latency_ms': 45.468675922130274, 'network_throughput_mbps': 460.34071525007084, 'disk_io_utilization': 0.18703951912984923, 'timestamp': 1742430219.524935, 'node_id': 'worker_4'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.4534567796436113, 'memory_utilization': 0.6870089396582427, 'network_latency_ms': 160.18637908766829, 'network_throughput_mbps': 128.3125136533604, 'disk_io_utilization': 0.173524829189069, 'timestamp': 1742430219.525106, 'node_id': 'worker_1'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.7109956349341255, 'memory_utilization': 0.7139237174654081, 'network_latency_ms': 81.22688655812802, 'network_throughput_mbps': 878.3372385595441, 'disk_io_utilization': 0.6758255515680205, 'timestamp': 1742430219.530238, 'node_id': 'worker_2'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.5209399286701439, 'memory_utilization': 0.6529707039776569, 'network_latency_ms': 121.92378229860547, 'network_throughput_mbps': 597.213051845425, 'disk_io_utilization': 0.5849113400216334, 'timestamp': 1742430219.534413, 'node_id': 'worker_3'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.34278740600837976, 'memory_utilization': 0.5110935766762692, 'network_latency_ms': 185.46623998621672, 'network_throughput_mbps': 501.2957124120144, 'disk_io_utilization': 0.28121483699372096, 'timestamp': 1742430224.528606, 'node_id': 'worker_4'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.34567609479450934, 'memory_utilization': 0.5966584988335808, 'network_latency_ms': 21.140847519925483, 'network_throughput_mbps': 407.6442837831808, 'disk_io_utilization': 0.6656604481919821, 'timestamp': 1742430224.5298848, 'node_id': 'worker_1'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.507960140057196, 'memory_utilization': 0.7394023092045362, 'network_latency_ms': 89.51973785697203, 'network_throughput_mbps': 915.8437219276773, 'disk_io_utilization': 0.3106211285714641, 'timestamp': 1742430224.5344179, 'node_id': 'worker_2'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.39826281955092907, 'memory_utilization': 0.7690432297233079, 'network_latency_ms': 66.66631441016344, 'network_throughput_mbps': 748.463881075093, 'disk_io_utilization': 0.6108954090353317, 'timestamp': 1742430224.536708, 'node_id': 'worker_3'}\n",
      "Updated Q-value for 5_6_6_3, balanced: 0.0 -> 0.0\n",
      "Updated model with reward 0.00 for action balanced\n",
      "Exploiting with action: balanced\n",
      "Sending to topic atm_commands: {'type': 'strategy_change', 'mode': 'balanced', 'timestamp': 1742430229.5272892, 'source_node': 'coordinator'}\n",
      "Node coordinator switching to balanced mode with params: {'local_compute_ratio': 0.5, 'network_batch_size': 1000, 'consistency_level': 'strong'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.30509240979315, 'memory_utilization': 0.508537402547134, 'network_latency_ms': 172.72444695419483, 'network_throughput_mbps': 172.65236596887814, 'disk_io_utilization': 0.30000387567420794, 'timestamp': 1742430229.534375, 'node_id': 'worker_4'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.9141758738416728, 'memory_utilization': 0.4979108176565479, 'network_latency_ms': 54.48312961852218, 'network_throughput_mbps': 554.4181315061713, 'disk_io_utilization': 0.4814009055718359, 'timestamp': 1742430229.5346649, 'node_id': 'worker_1'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.5338592685556137, 'memory_utilization': 0.47863488127467857, 'network_latency_ms': 75.73953287623954, 'network_throughput_mbps': 481.77201418559906, 'disk_io_utilization': 0.17976008078079586, 'timestamp': 1742430229.539849, 'node_id': 'worker_2'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.5276816836964398, 'memory_utilization': 0.7744788755091365, 'network_latency_ms': 68.64574018789335, 'network_throughput_mbps': 709.7531139914496, 'disk_io_utilization': 0.2359942466695379, 'timestamp': 1742430229.541867, 'node_id': 'worker_3'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.3740328374299622, 'memory_utilization': 0.7218205132732536, 'network_latency_ms': 90.74107227071575, 'network_throughput_mbps': 892.6900952033802, 'disk_io_utilization': 0.5432462587090832, 'timestamp': 1742430234.5376372, 'node_id': 'worker_4'}Sending to topic atm_metrics: {'cpu_utilization': 0.8565404019828595, 'memory_utilization': 0.7018938801931166, 'network_latency_ms': 62.33478524073512, 'network_throughput_mbps': 940.9190672065458, 'disk_io_utilization': 0.5478782860212024, 'timestamp': 1742430234.537805, 'node_id': 'worker_1'}\n",
      "\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.5909449759006998, 'memory_utilization': 0.6433401305667417, 'network_latency_ms': 102.93134414481612, 'network_throughput_mbps': 437.7430691377157, 'disk_io_utilization': 0.19387516490498224, 'timestamp': 1742430234.541763, 'node_id': 'worker_2'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.7628434628358316, 'memory_utilization': 0.6841946669250882, 'network_latency_ms': 129.89059208772088, 'network_throughput_mbps': 819.9852065306056, 'disk_io_utilization': 0.6385793745221608, 'timestamp': 1742430234.5456572, 'node_id': 'worker_3'}\n",
      "Updated Q-value for 3_7_6_7, balanced: 0.0 -> 0.0\n",
      "Updated model with reward 0.00 for action balanced\n",
      "Exploiting with action: balanced\n",
      "Sending to topic atm_commands: {'type': 'strategy_change', 'mode': 'balanced', 'timestamp': 1742430239.529, 'source_node': 'coordinator'}\n",
      "Node coordinator switching to balanced mode with params: {'local_compute_ratio': 0.5, 'network_batch_size': 1000, 'consistency_level': 'strong'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.6668493176783079, 'memory_utilization': 0.6781663841638181, 'network_latency_ms': 193.11310005952652, 'network_throughput_mbps': 498.08944892085856, 'disk_io_utilization': 0.6928129410913992, 'timestamp': 1742430239.541249, 'node_id': 'worker_4'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.7554883363551832, 'memory_utilization': 0.7657239361407121, 'network_latency_ms': 165.28939168431526, 'network_throughput_mbps': 402.74372297809106, 'disk_io_utilization': 0.6709134169068982, 'timestamp': 1742430239.5417469, 'node_id': 'worker_1'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.8270141735885033, 'memory_utilization': 0.411307138117272, 'network_latency_ms': 92.8346432474089, 'network_throughput_mbps': 504.26737401872265, 'disk_io_utilization': 0.5921982621441537, 'timestamp': 1742430239.5421, 'node_id': 'worker_2'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.3820518550359673, 'memory_utilization': 0.4347881561334332, 'network_latency_ms': 12.605124720422715, 'network_throughput_mbps': 63.183000036973056, 'disk_io_utilization': 0.6049965225002334, 'timestamp': 1742430239.550262, 'node_id': 'worker_3'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.4039413437697355, 'memory_utilization': 0.627434087281036, 'network_latency_ms': 92.71727285530739, 'network_throughput_mbps': 589.9714305177248, 'disk_io_utilization': 0.6672442889990892, 'timestamp': 1742430244.542659, 'node_id': 'worker_4'}Sending to topic atm_metrics: {'cpu_utilization': 0.8295650335075653, 'memory_utilization': 0.4200208286236598, 'network_latency_ms': 189.37484177217794, 'network_throughput_mbps': 664.8402314296227, 'disk_io_utilization': 0.2350290785837209, 'timestamp': 1742430244.542896, 'node_id': 'worker_1'}\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.8758913078923776, 'memory_utilization': 0.6492952242794618, 'network_latency_ms': 73.08068389565011, 'network_throughput_mbps': 296.17184248077416, 'disk_io_utilization': 0.30559802432701577, 'timestamp': 1742430244.5431218, 'node_id': 'worker_2'}\n",
      "\n",
      "Sending to topic atm_metrics: {'cpu_utilization': 0.3451754549786597, 'memory_utilization': 0.751954386839349, 'network_latency_ms': 27.735691721071763, 'network_throughput_mbps': 910.5747021144543, 'disk_io_utilization': 0.514317492672712, 'timestamp': 1742430244.550733, 'node_id': 'worker_3'}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main entry point for the ATM system\"\"\"\n",
    "    print(\"Starting Adaptive Trade-off Model (ATM) in federated mode\")\n",
    "    \n",
    "    # Create and start the cluster\n",
    "    cluster = ATMCluster(num_nodes=5)\n",
    "    \n",
    "    try:\n",
    "        cluster.start_cluster()\n",
    "        \n",
    "        # Run for a fixed time period\n",
    "        time.sleep(60)\n",
    "        \n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Shutdown signal received\")\n",
    "    finally:\n",
    "        cluster.shutdown_cluster()\n",
    "        print(\"ATM system shutdown complete\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f709049-3570-4e0e-baf5-54d876992fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3eaa75-42b1-4a40-b163-efbfafb0bf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
